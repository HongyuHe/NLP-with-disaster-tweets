{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>NYC,last week</td>\n",
       "      <td>ORG,DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Cooool :)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  keyword location                    text       entities    labels  \\\n",
       "20  31  missing  unknown  this is ridiculous....           None      None   \n",
       "22  33  missing  unknown             Love skiing           None      None   \n",
       "24  36  missing  unknown                LOOOOOOL           None      None   \n",
       "26  38  missing  unknown   Was in NYC last week!  NYC,last week  ORG,DATE   \n",
       "28  40  missing  unknown               Cooool :)           None      None   \n",
       "\n",
       "   ent_dep ent_head ent_pos ent_children  target  \n",
       "20    None     None    None         None       0  \n",
       "22    None     None    None         None       0  \n",
       "24    None     None    None         None       0  \n",
       "26    pobj       in     ADP         None       0  \n",
       "28    None     None    None         None       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/entities_nlp_train_hongyu.csv')\n",
    "df[20:30:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'entities', 'labels', 'ent_dep',\n",
       "       'ent_head', 'ent_pos', 'ent_children'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "class LabeledNormalizer(Normalizer):\n",
    "    def fit(self, X, *args, **kwargs):\n",
    "        try:\n",
    "            self.names = X.columns\n",
    "        except:\n",
    "            self.names = [str(i) for i in range(X.shape[1])]\n",
    "        return super().fit(X, *args, **kwargs)\n",
    "         \n",
    "    def get_feature_names(self):\n",
    "        return self.names\n",
    "    \n",
    "vec = ColumnTransformer([\n",
    "#     ('norm', LabeledNormalizer(), ['id']),\n",
    "    ('kw', TfidfVectorizer(ngram_range=(1, 1), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\",), 'keyword'),\n",
    "    ('loc', TfidfVectorizer(ngram_range=(1, 1), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'location'),\n",
    "    ('text', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'text'),\n",
    "    ('ent', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'entities'),\n",
    "    ('label', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'labels'),\n",
    "    ('dep', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_dep'),\n",
    "    ('head', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_head'),\n",
    "    ('pos', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_pos'),\n",
    "    ('child', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_children'),\n",
    "    \n",
    "])\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(2)\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='linear', probability=True)\n",
    "# clf = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=20, random_state=0) # use a guassian forest\n",
    "clf = RandomForestClassifier(n_estimators=200, max_features=250, random_state=0) # set limit to prevent overfitting\n",
    "# clf = RandomForestClassifier(n_estimators=200, max_features=1000, random_state=0) # set limit to prevent overfitting\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(vec, clf)\n",
    "# pipeline = make_pipeline(vec, poly, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time Taken:   00:00:42\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('Training Time Taken:  ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extend to 767869266 features (Training Time Taken:   00:15:48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38278"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline[1].get_feature_names()\n",
    "pipeline[1].n_features_\n",
    "# pipeline[1].n_output_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/bbkruit/academic-table-search/venv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 hhe450 hhe450 79M Mar 26 19:07 ../models/extend-770M-features.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "feature_mdl = '../models/extend-770M-features.pkl'\n",
    "joblib.dump(pipeline, feature_mdl)\n",
    "!ls -lSh $feature_mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      4342\n",
      "           1       0.76      0.41      0.54      3271\n",
      "\n",
      "    accuracy                           0.69      7613\n",
      "   macro avg       0.72      0.66      0.65      7613\n",
      "weighted avg       0.71      0.69      0.67      7613\n",
      "\n",
      "Cross-validation MSE: 0.693 ± 0.058\n",
      "Training Set Accuracy: 0.995\n",
      "\n",
      "Evaluation Time Taken:  00:05:21\n",
      "Training Time Taken:   00:00:39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def evaluate(_clf, X, y):\n",
    "    report = classification_report(\n",
    "        y_true=y, y_pred=cross_val_predict(_clf, X, y, cv=5)\n",
    "    )\n",
    "    print(report)\n",
    "    scores = cross_val_score(_clf, X, y, scoring='accuracy', cv=5)\n",
    "    print('Cross-validation MSE: {:.3f} ± {:.3f}'.format(np.mean(scores), 2 * np.std(scores)))\n",
    "    \n",
    "    _clf.fit(X,y)\n",
    "    print('Training Set Accuracy: {:.3f}'.format(_clf.score(X,y)))\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "evaluate(pipeline, X, y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('\\nEvaluation Time Taken: ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('Training Time Taken:  ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest\n",
    "\n",
    "### after limiting the features to 100:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.66      0.92      0.77      4342\n",
    "           1       0.77      0.38      0.51      3271\n",
    "\n",
    "    accuracy                           0.69      7613\n",
    "   macro avg       0.72      0.65      0.64      7613\n",
    "weighted avg       0.71      0.69      0.66      7613\n",
    "\n",
    "Cross-validation MSE: 0.687 ± 0.055\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:05:00\n",
    "```\n",
    "\n",
    "### after limiting the features to 250:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.67      0.90      0.77      4342\n",
    "           1       0.76      0.41      0.54      3271\n",
    "\n",
    "    accuracy                           0.69      7613\n",
    "   macro avg       0.72      0.66      0.65      7613\n",
    "weighted avg       0.71      0.69      0.67      7613\n",
    "\n",
    "Cross-validation MSE: 0.693 ± 0.058\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:05:21\n",
    "Training Time Taken:   00:00:39\n",
    "```\n",
    "\n",
    "### after limiting the features to 500:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.68      0.89      0.77      4342\n",
    "           1       0.76      0.43      0.55      3271\n",
    "\n",
    "    accuracy                           0.70      7613\n",
    "   macro avg       0.72      0.66      0.66      7613\n",
    "weighted avg       0.71      0.70      0.68      7613\n",
    "\n",
    "Cross-validation MSE: 0.697 ± 0.054\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:05:27\n",
    "Training Time Taken:   00:00:41\n",
    "```\n",
    "\n",
    "### after limiting the features to 1k:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.68      0.88      0.77      4342\n",
    "           1       0.74      0.45      0.56      3271\n",
    "\n",
    "    accuracy                           0.70      7613\n",
    "   macro avg       0.71      0.67      0.66      7613\n",
    "weighted avg       0.71      0.70      0.68      7613\n",
    "\n",
    "Cross-validation MSE: 0.696 ± 0.054\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:06:12\n",
    "Training Time Taken:   00:00:45\n",
    "```\n",
    "\n",
    "### 200 trees (original features):\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.67      0.91      0.77      4342\n",
    "           1       0.77      0.41      0.53      3271\n",
    "\n",
    "    accuracy                           0.69      7613\n",
    "   macro avg       0.72      0.66      0.65      7613\n",
    "weighted avg       0.71      0.69      0.67      7613\n",
    "\n",
    "Cross-validation MSE: 0.692 ± 0.066\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:05:43\n",
    "Training Time Taken:   00:00:45\n",
    "```\n",
    "\n",
    "### 20 trees (original features):\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.66      0.90      0.76      4342\n",
    "           1       0.75      0.39      0.51      3271\n",
    "\n",
    "    accuracy                           0.68      7613\n",
    "   macro avg       0.71      0.65      0.64      7613\n",
    "weighted avg       0.70      0.68      0.66      7613\n",
    "\n",
    "Cross-validation MSE: 0.682 ± 0.060\n",
    "Training Set Accuracy: 0.987\n",
    "\n",
    "Evaluation Time Taken:  00:00:49\n",
    "Training Time Taken:   00:00:05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rbf kernel\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.65      0.85      0.74      4342\n",
    "           1       0.67      0.40      0.50      3271\n",
    "\n",
    "    accuracy                           0.66      7613\n",
    "   macro avg       0.66      0.63      0.62      7613\n",
    "weighted avg       0.66      0.66      0.64      7613\n",
    "\n",
    "Cross-validation MSE: 0.657 ± 0.070\n",
    "Training Set Accuracy: 0.902\n",
    "\n",
    "Evaluation Time Taken: 00:09:49\n",
    "Training Time Taken:   00:01:21\n",
    "```\n",
    "### SVC with rbf kernel (770M features)\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.65      0.87      0.74      4342\n",
    "           1       0.69      0.38      0.49      3271\n",
    "\n",
    "    accuracy                           0.66      7613\n",
    "   macro avg       0.67      0.62      0.62      7613\n",
    "weighted avg       0.67      0.66      0.63      7613\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "1. Blindly adding extending feature space doesn't help even using non-linear kernel;\n",
    "2. After extending the features, training the random forest takes forever;\n",
    "3. Get noticeable performance gain by limiting  the number of considered features;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
