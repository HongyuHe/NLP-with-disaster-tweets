{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../raw')\n",
    "# sys.path.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooool :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The end!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>54</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Pretoria</td>\n",
       "      <td>@PhDSquares #mufc they've built so much hype a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>56</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "20  31     NaN                            NaN   \n",
       "22  33     NaN                            NaN   \n",
       "24  36     NaN                            NaN   \n",
       "26  38     NaN                            NaN   \n",
       "28  40     NaN                            NaN   \n",
       "30  44     NaN                            NaN   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "36  54  ablaze                       Pretoria   \n",
       "38  56  ablaze                            NaN   \n",
       "\n",
       "                                                 text  target  \n",
       "20                             this is ridiculous....       0  \n",
       "22                                        Love skiing       0  \n",
       "24                                           LOOOOOOL       0  \n",
       "26                              Was in NYC last week!       0  \n",
       "28                                          Cooool :)       0  \n",
       "30                                           The end!       0  \n",
       "32  We always try to bring the heavy. #metal #RT h...       0  \n",
       "34                 Crying out for more! Set me ablaze       0  \n",
       "36  @PhDSquares #mufc they've built so much hype a...       0  \n",
       "38  Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(sys.path[0]+('/train.csv'))\n",
    "train_df[20:40:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "  entities labels  \n",
       "0                  \n",
       "1                  \n",
       "2                  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_v = {'keyword': 'missing', 'location': 'unknown'}\n",
    "filled_df = train_df.fillna(value=fill_v)\n",
    "filled_df = filled_df.drop(['target'], axis=1)\n",
    "\n",
    "filled_df.insert(4, 'entities','',True)\n",
    "filled_df.insert(5, 'labels','',True)\n",
    "filled_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using `spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add entities and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7613it [01:14, 101.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ent_df = filled_df.copy()\n",
    "for ri, row in tqdm(ent_df.iterrows()):\n",
    "    doc = nlp(row['text'])\n",
    "    ents = []\n",
    "    labels = []\n",
    "    for ent in doc.ents:\n",
    "#         print(ent.text)\n",
    "        if ent.text not in ents:\n",
    "            ents.append(ent.text)\n",
    "        if ent.label_ not in labels:\n",
    "            labels.append(ent.label_)\n",
    "            \n",
    "    ent_df.at[ri, 'entities'] = ','.join(ents)\n",
    "    ent_df.at[ri, 'labels'] = ','.join(labels)\n",
    "        \n",
    "#     ent_df.at[ri, 'entities'] += row['entities'] + ent.text+ \",\"\n",
    "#     ent_df.at[ri, 'labels'] += row['labels'] + ent.label_+ \",\"\n",
    "#     print()\n",
    "#     if ri > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels  \n",
       "0                 Deeds        PERSON  \n",
       "1  La Ronge Sask,Canada       FAC,GPE  \n",
       "2                                      \n",
       "3     13,000,California  CARDINAL,GPE  \n",
       "4          Ruby #Alaska        PERSON  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels ent_dep ent_head ent_pos ent_children  \n",
       "0                 Deeds        PERSON                                        \n",
       "1  La Ronge Sask,Canada       FAC,GPE                                        \n",
       "2                                                                            \n",
       "3     13,000,California  CARDINAL,GPE                                        \n",
       "4          Ruby #Alaska        PERSON                                        "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df = ent_df.copy()\n",
    "nlp_df.insert(6, 'ent_dep', '', True)\n",
    "nlp_df.insert(7, 'ent_head', '', True)\n",
    "nlp_df.insert(8, 'ent_pos', '', True)\n",
    "nlp_df.insert(9, 'ent_children', '', True)\n",
    "nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ri, row in nlp_df.iterrows():\n",
    "    doc = nlp(row['text'])\n",
    "    entities = [ent_tok.lower() for ent_tok in row['entities'].split(',') if ent_tok]\n",
    "#     print(entities)\n",
    "    deps = []\n",
    "    heads =[]\n",
    "    positions = [] \n",
    "    children = set()\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text.lower() in entities:\n",
    "#             print(token.text.lower())\n",
    "            if token.dep_ not in deps:\n",
    "                deps.append(token.dep_)\n",
    "            if token.head.text not in heads:\n",
    "                heads.append(token.head.text)\n",
    "            if token.head.pos_ not in positions:\n",
    "                positions.append(token.head.pos_)\n",
    "                \n",
    "            children = children.union([child.text for child in token.children])\n",
    "            \n",
    "#             nlp_df.at[ri, 'ent_dep'] = row['ent_dep'] + token.dep_ + \",\"\n",
    "#             nlp_df.at[ri, 'ent_head'] += row['ent_head'] + token.head.text + \",\"\n",
    "#             nlp_df.at[ri, 'ent_pos'] += row['ent_pos'] + token.head.pos_ + \",\"\n",
    "#             nlp_df.at[ri, 'ent_children'] += row['ent_children'] + ','.join([child.text for child in token.children])+','\n",
    "    nlp_df.at[ri, 'ent_dep'] = ','.join(deps)\n",
    "    nlp_df.at[ri, 'ent_head'] = ','.join(heads)\n",
    "    nlp_df.at[ri, 'ent_pos'] = ','.join(positions)\n",
    "    nlp_df.at[ri, 'ent_children'] = ','.join(children)\n",
    "            \n",
    "#     if ri > 5:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>Our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>RockyFire,California Hwy,20,Lake County</td>\n",
       "      <td>PERSON,ORG,CARDINAL,GPE</td>\n",
       "      <td>compound,nummod</td>\n",
       "      <td>Update,.</td>\n",
       "      <td>PROPN,PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>Manitou,Colorado Springs</td>\n",
       "      <td>GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>Three</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>nummod</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>Haha South Tampa</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>#raining,#Florida,Tampa,18 or 19 days</td>\n",
       "      <td>MONEY,GPE,DATE</td>\n",
       "      <td>dobj</td>\n",
       "      <td>flooding</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>TampaBay,days,#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>Flood,Bago Myanmar</td>\n",
       "      <td>PERSON,GPE</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>#</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>in,#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>80</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>pobj</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  keyword location                                               text  \\\n",
       "0    1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1    4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2    5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3    6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4    7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5    8  missing  unknown  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6   10  missing  unknown  #flood #disaster Heavy rain causes flash flood...   \n",
       "7   13  missing  unknown  I'm on top of the hill and I can see a fire in...   \n",
       "8   14  missing  unknown  There's an emergency evacuation happening now ...   \n",
       "9   15  missing  unknown  I'm afraid that the tornado is coming to our a...   \n",
       "10  16  missing  unknown        Three people died from the heat wave so far   \n",
       "11  17  missing  unknown  Haha South Tampa is getting flooded hah- WAIT ...   \n",
       "12  18  missing  unknown  #raining #flooding #Florida #TampaBay #Tampa 1...   \n",
       "13  19  missing  unknown            #Flood in Bago Myanmar #We arrived Bago   \n",
       "14  20  missing  unknown  Damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "                                   entities                   labels  \\\n",
       "0                                     Deeds                   PERSON   \n",
       "1                      La Ronge Sask,Canada                  FAC,GPE   \n",
       "2                                                                      \n",
       "3                         13,000,California             CARDINAL,GPE   \n",
       "4                              Ruby #Alaska                   PERSON   \n",
       "5   RockyFire,California Hwy,20,Lake County  PERSON,ORG,CARDINAL,GPE   \n",
       "6                  Manitou,Colorado Springs                      GPE   \n",
       "7                                                                      \n",
       "8                                                                      \n",
       "9                                                                      \n",
       "10                                    Three                 CARDINAL   \n",
       "11                         Haha South Tampa                   PERSON   \n",
       "12    #raining,#Florida,Tampa,18 or 19 days           MONEY,GPE,DATE   \n",
       "13                       Flood,Bago Myanmar               PERSON,GPE   \n",
       "14                                       80                 CARDINAL   \n",
       "\n",
       "            ent_dep  ent_head      ent_pos     ent_children  \n",
       "0             nsubj       are          AUX              Our  \n",
       "1              ROOT    Canada        PROPN                   \n",
       "2                                                            \n",
       "3              pobj        in          ADP                   \n",
       "4                                                            \n",
       "5   compound,nummod  Update,.  PROPN,PUNCT                   \n",
       "6              pobj        in          ADP                   \n",
       "7                                                            \n",
       "8                                                            \n",
       "9                                                            \n",
       "10           nummod    people         NOUN                   \n",
       "11                                                           \n",
       "12             dobj  flooding         NOUN  TampaBay,days,#  \n",
       "13            nsubj         #        PROPN             in,#  \n",
       "14             pobj        on          ADP               in  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 10)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nlp_df.copy()\n",
    "\n",
    "X.join(y).to_csv('../datasets/entities_nlp_train_hongyu.csv')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>Our</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels ent_dep ent_head ent_pos ent_children  \\\n",
       "0                 Deeds        PERSON   nsubj      are     AUX          Our   \n",
       "1  La Ronge Sask,Canada       FAC,GPE    ROOT   Canada   PROPN          NaN   \n",
       "2                   NaN           NaN     NaN      NaN     NaN          NaN   \n",
       "3     13,000,California  CARDINAL,GPE    pobj       in     ADP          NaN   \n",
       "4          Ruby #Alaska        PERSON     NaN      NaN     NaN          NaN   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/entities_nlp_train_hongyu.csv', index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>Our</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels ent_dep ent_head ent_pos ent_children  \\\n",
       "0                 Deeds        PERSON   nsubj      are     AUX          Our   \n",
       "1  La Ronge Sask,Canada       FAC,GPE    ROOT   Canada   PROPN         None   \n",
       "2                  None          None    None     None    None         None   \n",
       "3     13,000,California  CARDINAL,GPE    pobj       in     ADP         None   \n",
       "4          Ruby #Alaska        PERSON    None     None    None         None   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillers = {'entities':'None', 'labels':'None', 'ent_dep':'None', 'ent_head':'None', 'ent_pos':'None', 'ent_children':'None'}\n",
    "df = df.fillna(value=fillers)\n",
    "df.to_csv('../datasets/entities_nlp_train_hongyu.csv', index=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'entities', 'labels', 'ent_dep',\n",
       "       'ent_head', 'ent_pos', 'ent_children'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardinal', 'fac', 'gpe', 'none', 'org', 'person']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "x = vectorizer.fit_transform(X['labels'][:10])\n",
    "# x.toarray()\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "class LabeledNormalizer(Normalizer):\n",
    "    def fit(self, X, *args, **kwargs):\n",
    "        try:\n",
    "            self.names = X.columns\n",
    "        except:\n",
    "            self.names = [str(i) for i in range(X.shape[1])]\n",
    "        return super().fit(X, *args, **kwargs)\n",
    "         \n",
    "    def get_feature_names(self):\n",
    "        return self.names\n",
    "    \n",
    "vec = ColumnTransformer([\n",
    "#     ('norm', LabeledNormalizer(), ['id']),\n",
    "    ('kw', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\",), 'keyword'),\n",
    "    ('loc', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'location'),\n",
    "    ('text', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'text'),\n",
    "    ('ent', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'entities'),\n",
    "    ('label', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'labels'),\n",
    "    ('dep', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_dep'),\n",
    "    ('head', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_head'),\n",
    "    ('pos', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_pos'),\n",
    "    ('child', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_children'),\n",
    "    \n",
    "])\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', probability=True) # 1.\n",
    "# clf = SVC(kernel='rbf', probability=True) # 2.\n",
    "# clf = LinearSVC(verbose=True)\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(vec, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. hyper`C`=1, `kernel`=linear, `gamma`=scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67      4342\n",
      "           1       0.55      0.52      0.54      3271\n",
      "\n",
      "    accuracy                           0.61      7613\n",
      "   macro avg       0.60      0.60      0.60      7613\n",
      "weighted avg       0.61      0.61      0.61      7613\n",
      "\n",
      "Cross-validation Accuracy: 0.516 ± 0.197\n",
      "Training Set Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def evaluate(_clf, X, y):\n",
    "    report = classification_report(\n",
    "        y_true=y, y_pred=cross_val_predict(pipeline, X, y, cv=5)\n",
    "    )\n",
    "    print(report)\n",
    "    scores = cross_val_score(_clf, X, y, scoring='accuracy', cv=10)\n",
    "    print('Cross-validation Accuracy: {:.3f} ± {:.3f}'.format(np.mean(scores), 2 * np.std(scores)))\n",
    "    \n",
    "    _clf.fit(X,y)\n",
    "    print('Training Set Accuracy: {:.3f}'.format(_clf.score(X,y)))\n",
    "\n",
    "\n",
    "evaluate(pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 hongyu hongyu 8.2M Mar 17 21:54 ../models/nlp-entity-linear-svc.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "entity_mdl = '../models/nlp-entity-linear-svc.pkl'\n",
    "joblib.dump(pipeline, entity_mdl)\n",
    "!ls -lSh $entity_mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. hyper`C`=10, `kernel`=rbf, `gamma`=auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `kernel`=rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-723c2f99367e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-723c2f99367e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(_clf, X, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     report = classification_report(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    754\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 755\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def evaluate(_clf, X, y):\n",
    "    report = classification_report(\n",
    "        y_true=y, y_pred=cross_val_predict(pipeline, X, y, cv=5)\n",
    "    )\n",
    "    print(report)\n",
    "    scores = cross_val_score(_clf, X, y, scoring='accuracy', cv=10)\n",
    "    print('Cross-validation Accuracy: {:.3f} ± {:.3f}'.format(np.mean(scores), 2 * np.std(scores)))\n",
    "    \n",
    "    _clf.fit(X,y)\n",
    "    print('Training Set Accuracy: {:.3f}'.format(_clf.score(X,y)))\n",
    "\n",
    "\n",
    "evaluate(pipeline, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
