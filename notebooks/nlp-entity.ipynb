{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../raw')\n",
    "# sys.path.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooool :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The end!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>54</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Pretoria</td>\n",
       "      <td>@PhDSquares #mufc they've built so much hype a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>56</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "20  31     NaN                            NaN   \n",
       "22  33     NaN                            NaN   \n",
       "24  36     NaN                            NaN   \n",
       "26  38     NaN                            NaN   \n",
       "28  40     NaN                            NaN   \n",
       "30  44     NaN                            NaN   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "36  54  ablaze                       Pretoria   \n",
       "38  56  ablaze                            NaN   \n",
       "\n",
       "                                                 text  target  \n",
       "20                             this is ridiculous....       0  \n",
       "22                                        Love skiing       0  \n",
       "24                                           LOOOOOOL       0  \n",
       "26                              Was in NYC last week!       0  \n",
       "28                                          Cooool :)       0  \n",
       "30                                           The end!       0  \n",
       "32  We always try to bring the heavy. #metal #RT h...       0  \n",
       "34                 Crying out for more! Set me ablaze       0  \n",
       "36  @PhDSquares #mufc they've built so much hype a...       0  \n",
       "38  Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(sys.path[0]+('/train.csv'))\n",
    "train_df[20:40:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "  entities labels  \n",
       "0                  \n",
       "1                  \n",
       "2                  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_v = {'keyword': 'missing', 'location': 'unknown'}\n",
    "filled_df = train_df.fillna(value=fill_v)\n",
    "filled_df = filled_df.drop(['target'], axis=1)\n",
    "\n",
    "filled_df.insert(4, 'entities','',True)\n",
    "filled_df.insert(5, 'labels','',True)\n",
    "filled_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using `spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add entities and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7613it [01:14, 101.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ent_df = filled_df.copy()\n",
    "for ri, row in tqdm(ent_df.iterrows()):\n",
    "    doc = nlp(row['text'])\n",
    "    ents = []\n",
    "    labels = []\n",
    "    for ent in doc.ents:\n",
    "#         print(ent.text)\n",
    "        if ent.text not in ents:\n",
    "            ents.append(ent.text)\n",
    "        if ent.label_ not in labels:\n",
    "            labels.append(ent.label_)\n",
    "            \n",
    "    ent_df.at[ri, 'entities'] = ','.join(ents)\n",
    "    ent_df.at[ri, 'labels'] = ','.join(labels)\n",
    "        \n",
    "#     ent_df.at[ri, 'entities'] += row['entities'] + ent.text+ \",\"\n",
    "#     ent_df.at[ri, 'labels'] += row['labels'] + ent.label_+ \",\"\n",
    "#     print()\n",
    "#     if ri > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels  \n",
       "0                 Deeds        PERSON  \n",
       "1  La Ronge Sask,Canada       FAC,GPE  \n",
       "2                                      \n",
       "3     13,000,California  CARDINAL,GPE  \n",
       "4          Ruby #Alaska        PERSON  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels ent_dep ent_head ent_pos ent_children  \n",
       "0                 Deeds        PERSON                                        \n",
       "1  La Ronge Sask,Canada       FAC,GPE                                        \n",
       "2                                                                            \n",
       "3     13,000,California  CARDINAL,GPE                                        \n",
       "4          Ruby #Alaska        PERSON                                        "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df = ent_df.copy()\n",
    "nlp_df.insert(6, 'ent_dep', '', True)\n",
    "nlp_df.insert(7, 'ent_head', '', True)\n",
    "nlp_df.insert(8, 'ent_pos', '', True)\n",
    "nlp_df.insert(9, 'ent_children', '', True)\n",
    "nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ri, row in nlp_df.iterrows():\n",
    "    doc = nlp(row['text'])\n",
    "    entities = [ent_tok.lower() for ent_tok in row['entities'].split(',') if ent_tok]\n",
    "#     print(entities)\n",
    "    deps = []\n",
    "    heads =[]\n",
    "    positions = [] \n",
    "    children = set()\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text.lower() in entities:\n",
    "#             print(token.text.lower())\n",
    "            if token.dep_ not in deps:\n",
    "                deps.append(token.dep_)\n",
    "            if token.head.text not in heads:\n",
    "                heads.append(token.head.text)\n",
    "            if token.head.pos_ not in positions:\n",
    "                positions.append(token.head.pos_)\n",
    "                \n",
    "            children = children.union([child.text for child in token.children])\n",
    "            \n",
    "#             nlp_df.at[ri, 'ent_dep'] = row['ent_dep'] + token.dep_ + \",\"\n",
    "#             nlp_df.at[ri, 'ent_head'] += row['ent_head'] + token.head.text + \",\"\n",
    "#             nlp_df.at[ri, 'ent_pos'] += row['ent_pos'] + token.head.pos_ + \",\"\n",
    "#             nlp_df.at[ri, 'ent_children'] += row['ent_children'] + ','.join([child.text for child in token.children])+','\n",
    "    nlp_df.at[ri, 'ent_dep'] = ','.join(deps)\n",
    "    nlp_df.at[ri, 'ent_head'] = ','.join(heads)\n",
    "    nlp_df.at[ri, 'ent_pos'] = ','.join(positions)\n",
    "    nlp_df.at[ri, 'ent_children'] = ','.join(children)\n",
    "            \n",
    "#     if ri > 5:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>Our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>RockyFire,California Hwy,20,Lake County</td>\n",
       "      <td>PERSON,ORG,CARDINAL,GPE</td>\n",
       "      <td>compound,nummod</td>\n",
       "      <td>Update,.</td>\n",
       "      <td>PROPN,PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>Manitou,Colorado Springs</td>\n",
       "      <td>GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>Three</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>nummod</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>Haha South Tampa</td>\n",
       "      <td>PERSON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>#raining,#Florida,Tampa,18 or 19 days</td>\n",
       "      <td>MONEY,GPE,DATE</td>\n",
       "      <td>dobj</td>\n",
       "      <td>flooding</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>TampaBay,days,#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>Flood,Bago Myanmar</td>\n",
       "      <td>PERSON,GPE</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>#</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>in,#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>80</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>pobj</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  keyword location                                               text  \\\n",
       "0    1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1    4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2    5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3    6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4    7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5    8  missing  unknown  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6   10  missing  unknown  #flood #disaster Heavy rain causes flash flood...   \n",
       "7   13  missing  unknown  I'm on top of the hill and I can see a fire in...   \n",
       "8   14  missing  unknown  There's an emergency evacuation happening now ...   \n",
       "9   15  missing  unknown  I'm afraid that the tornado is coming to our a...   \n",
       "10  16  missing  unknown        Three people died from the heat wave so far   \n",
       "11  17  missing  unknown  Haha South Tampa is getting flooded hah- WAIT ...   \n",
       "12  18  missing  unknown  #raining #flooding #Florida #TampaBay #Tampa 1...   \n",
       "13  19  missing  unknown            #Flood in Bago Myanmar #We arrived Bago   \n",
       "14  20  missing  unknown  Damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "                                   entities                   labels  \\\n",
       "0                                     Deeds                   PERSON   \n",
       "1                      La Ronge Sask,Canada                  FAC,GPE   \n",
       "2                                                                      \n",
       "3                         13,000,California             CARDINAL,GPE   \n",
       "4                              Ruby #Alaska                   PERSON   \n",
       "5   RockyFire,California Hwy,20,Lake County  PERSON,ORG,CARDINAL,GPE   \n",
       "6                  Manitou,Colorado Springs                      GPE   \n",
       "7                                                                      \n",
       "8                                                                      \n",
       "9                                                                      \n",
       "10                                    Three                 CARDINAL   \n",
       "11                         Haha South Tampa                   PERSON   \n",
       "12    #raining,#Florida,Tampa,18 or 19 days           MONEY,GPE,DATE   \n",
       "13                       Flood,Bago Myanmar               PERSON,GPE   \n",
       "14                                       80                 CARDINAL   \n",
       "\n",
       "            ent_dep  ent_head      ent_pos     ent_children  \n",
       "0             nsubj       are          AUX              Our  \n",
       "1              ROOT    Canada        PROPN                   \n",
       "2                                                            \n",
       "3              pobj        in          ADP                   \n",
       "4                                                            \n",
       "5   compound,nummod  Update,.  PROPN,PUNCT                   \n",
       "6              pobj        in          ADP                   \n",
       "7                                                            \n",
       "8                                                            \n",
       "9                                                            \n",
       "10           nummod    people         NOUN                   \n",
       "11                                                           \n",
       "12             dobj  flooding         NOUN  TampaBay,days,#  \n",
       "13            nsubj         #        PROPN             in,#  \n",
       "14             pobj        on          ADP               in  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 10)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nlp_df.copy()\n",
    "\n",
    "X.join(y).to_csv('../datasets/entities_nlp_train_hongyu.csv')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>Our</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels ent_dep ent_head ent_pos ent_children  \\\n",
       "0                 Deeds        PERSON   nsubj      are     AUX          Our   \n",
       "1  La Ronge Sask,Canada       FAC,GPE    ROOT   Canada   PROPN          NaN   \n",
       "2                   NaN           NaN     NaN      NaN     NaN          NaN   \n",
       "3     13,000,California  CARDINAL,GPE    pobj       in     ADP          NaN   \n",
       "4          Ruby #Alaska        PERSON     NaN      NaN     NaN          NaN   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/entities_nlp_train_hongyu.csv', index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>Our</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>La Ronge Sask,Canada</td>\n",
       "      <td>FAC,GPE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000,California</td>\n",
       "      <td>CARDINAL,GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Ruby #Alaska</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  missing  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  missing  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  missing  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  missing  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  missing  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "               entities        labels ent_dep ent_head ent_pos ent_children  \\\n",
       "0                 Deeds        PERSON   nsubj      are     AUX          Our   \n",
       "1  La Ronge Sask,Canada       FAC,GPE    ROOT   Canada   PROPN         None   \n",
       "2                  None          None    None     None    None         None   \n",
       "3     13,000,California  CARDINAL,GPE    pobj       in     ADP         None   \n",
       "4          Ruby #Alaska        PERSON    None     None    None         None   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillers = {'entities':'None', 'labels':'None', 'ent_dep':'None', 'ent_head':'None', 'ent_pos':'None', 'ent_children':'None'}\n",
    "df = df.fillna(value=fillers)\n",
    "df.to_csv('../datasets/entities_nlp_train_hongyu.csv', index=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../datasets/entities_nlp_train_hongyu.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keyword', 'location', 'text', 'entities', 'labels', 'ent_dep',\n",
       "       'ent_head', 'ent_pos', 'ent_children'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardinal', 'fac', 'gpe', 'none', 'org', 'person']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "x = vectorizer.fit_transform(X['labels'][:10])\n",
    "# x.toarray()\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "class LabeledNormalizer(Normalizer):\n",
    "    def fit(self, X, *args, **kwargs):\n",
    "        try:\n",
    "            self.names = X.columns\n",
    "        except:\n",
    "            self.names = [str(i) for i in range(X.shape[1])]\n",
    "        return super().fit(X, *args, **kwargs)\n",
    "         \n",
    "    def get_feature_names(self):\n",
    "        return self.names\n",
    "    \n",
    "vec = ColumnTransformer([\n",
    "#     ('norm', LabeledNormalizer(), ['id']),\n",
    "    ('kw', TfidfVectorizer(ngram_range=(1, 1), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\",), 'keyword'),\n",
    "    ('loc', TfidfVectorizer(ngram_range=(1, 1), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'location'),\n",
    "    ('text', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'text'),\n",
    "    ('ent', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'entities'),\n",
    "    ('label', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'labels'),\n",
    "    ('dep', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_dep'),\n",
    "    ('head', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_head'),\n",
    "    ('pos', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_pos'),\n",
    "    ('child', CountVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_children'),\n",
    "    \n",
    "])\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='linear', probability=True)\n",
    "clf = SVC(kernel='rbf', probability=True)\n",
    "# clf = SVC(kernel='poly', probability=True)\n",
    "# clf = SVC(kernel='sigmoid', probability=True)\n",
    "# clf = LinearSVC(verbose=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "pipeline = make_pipeline(vec, scaler, clf)\n",
    "\n",
    "# pipeline = make_pipeline(vec, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.96      0.77      4342\n",
      "           1       0.85      0.30      0.44      3271\n",
      "\n",
      "    accuracy                           0.67      7613\n",
      "   macro avg       0.75      0.63      0.61      7613\n",
      "weighted avg       0.73      0.67      0.63      7613\n",
      "\n",
      "Cross-validation MSE: 0.675 ± 0.035\n",
      "Training Set Accuracy: 0.954\n",
      "\n",
      "Evaluation Time Taken:  00:17:35\n",
      "Training Time Taken:   00:02:12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def evaluate(_clf, X, y):\n",
    "    report = classification_report(\n",
    "        y_true=y, y_pred=cross_val_predict(pipeline, X, y, cv=5)\n",
    "    )\n",
    "    print(report)\n",
    "    scores = cross_val_score(_clf, X, y, scoring='accuracy', cv=5)\n",
    "    print('Cross-validation MSE: {:.3f} ± {:.3f}'.format(np.mean(scores), 2 * np.std(scores)))\n",
    "    \n",
    "    _clf.fit(X,y)\n",
    "    print('Training Set Accuracy: {:.3f}'.format(_clf.score(X,y)))\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "evaluate(pipeline, X, y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('\\nEvaluation Time Taken: ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('Training Time Taken:  ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear kernel\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.65      0.68      0.67      4342\n",
    "           1       0.55      0.52      0.54      3271\n",
    "\n",
    "    accuracy                           0.61      7613\n",
    "   macro avg       0.60      0.60      0.60      7613\n",
    "weighted avg       0.61      0.61      0.61      7613\n",
    "\n",
    "Cross-validation MSE: 0.612 ± 0.087\n",
    "Training Set Accuracy: 0.975\n",
    "\n",
    "Evaluation Time Taken: 00:10:52\n",
    "Training Time Taken:   00:01:41\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rbf kernel\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.65      0.85      0.74      4342\n",
    "           1       0.67      0.40      0.50      3271\n",
    "\n",
    "    accuracy                           0.66      7613\n",
    "   macro avg       0.66      0.63      0.62      7613\n",
    "weighted avg       0.66      0.66      0.64      7613\n",
    "\n",
    "Cross-validation MSE: 0.657 ± 0.070\n",
    "Training Set Accuracy: 0.902\n",
    "\n",
    "Evaluation Time Taken: 00:09:49\n",
    "Training Time Taken:   00:01:21\n",
    "```\n",
    "\n",
    "### after scaling\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.64      0.96      0.77      4342\n",
    "           1       0.85      0.30      0.44      3271\n",
    "\n",
    "    accuracy                           0.67      7613\n",
    "   macro avg       0.75      0.63      0.61      7613\n",
    "weighted avg       0.73      0.67      0.63      7613\n",
    "\n",
    "Cross-validation MSE: 0.675 ± 0.035\n",
    "Training Set Accuracy: 0.954\n",
    "\n",
    "Evaluation Time Taken:  00:17:35\n",
    "Training Time Taken:   00:02:12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polynomial kernel\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.64      0.92      0.75      4342\n",
    "           1       0.74      0.30      0.43      3271\n",
    "\n",
    "    accuracy                           0.65      7613\n",
    "   macro avg       0.69      0.61      0.59      7613\n",
    "weighted avg       0.68      0.65      0.61      7613\n",
    "\n",
    "Cross-validation MSE: 0.655 ± 0.035\n",
    "Training Set Accuracy: 0.873\n",
    "\n",
    "Evaluation Time Taken: 00:11:37\n",
    "Training Time Taken:   00:01:15\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid kernel\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.63      0.69      0.66      4342\n",
    "           1       0.53      0.45      0.49      3271\n",
    "\n",
    "    accuracy                           0.59      7613\n",
    "   macro avg       0.58      0.57      0.57      7613\n",
    "weighted avg       0.58      0.59      0.58      7613\n",
    "\n",
    "Cross-validation MSE: 0.590 ± 0.039\n",
    "Training Set Accuracy: 0.768\n",
    "\n",
    "Evaluation Time Taken:  00:09:07\n",
    "Training Time Taken:   00:01:09\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 hongyu hongyu 8.2M Mar 21 12:50 ../models/nlp-entity-linear-svc.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline.fit(X,y)\n",
    "\n",
    "entity_mdl = '../models/nlp-entity-linear-svc.pkl'\n",
    "joblib.dump(pipeline, entity_mdl)\n",
    "!ls -lSh $entity_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 hongyu hongyu 8.9M Mar 21 12:48 ../models/nlp-entity-rbf-svc.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "entity_rbf_mdl = '../models/nlp-entity-rbf-svc.pkl'\n",
    "joblib.dump(pipeline, entity_rbf_mdl)\n",
    "!ls -lSh $entity_rbf_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 hongyu hongyu 9.1M Mar 21 13:19 ../models/nlp-entity-poly-svc.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "entity_poly_mdl = '../models/nlp-entity-poly-svc.pkl'\n",
    "joblib.dump(pipeline, entity_poly_mdl)\n",
    "!ls -lSh $entity_poly_mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "1. Entity-features extracted by the NLP library do make a positive effect on prediction;\n",
    "2. However, based on the performance of the linear kernel, it seems that the feature space is no longer linearly separatable;\n",
    "3. As a corollary, non-linear kernels performed better than the linear one;\n",
    "4. However, the performance of sigmoid kernel is exceptionaly bad;\n",
    "\n",
    "# Future works:\n",
    "1. We should consider continuing adding new features;\n",
    "2. Improve performance by tuning hyper-parameters is worth to try. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
