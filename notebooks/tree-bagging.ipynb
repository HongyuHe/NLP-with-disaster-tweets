{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "      <th>ent_dep</th>\n",
       "      <th>ent_head</th>\n",
       "      <th>ent_pos</th>\n",
       "      <th>ent_children</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>NYC,last week</td>\n",
       "      <td>ORG,DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>missing</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Cooool :)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  keyword location                    text       entities    labels  \\\n",
       "20  31  missing  unknown  this is ridiculous....           None      None   \n",
       "22  33  missing  unknown             Love skiing           None      None   \n",
       "24  36  missing  unknown                LOOOOOOL           None      None   \n",
       "26  38  missing  unknown   Was in NYC last week!  NYC,last week  ORG,DATE   \n",
       "28  40  missing  unknown               Cooool :)           None      None   \n",
       "\n",
       "   ent_dep ent_head ent_pos ent_children  target  \n",
       "20    None     None    None         None       0  \n",
       "22    None     None    None         None       0  \n",
       "24    None     None    None         None       0  \n",
       "26    pobj       in     ADP         None       0  \n",
       "28    None     None    None         None       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/entities_nlp_train_hongyu.csv')\n",
    "df[20:30:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'entities', 'labels', 'ent_dep',\n",
       "       'ent_head', 'ent_pos', 'ent_children'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "class LabeledNormalizer(Normalizer):\n",
    "    def fit(self, X, *args, **kwargs):\n",
    "        try:\n",
    "            self.names = X.columns\n",
    "        except:\n",
    "            self.names = [str(i) for i in range(X.shape[1])]\n",
    "        return super().fit(X, *args, **kwargs)\n",
    "         \n",
    "    def get_feature_names(self):\n",
    "        return self.names\n",
    "    \n",
    "vec = ColumnTransformer([\n",
    "#     ('norm', LabeledNormalizer(), ['id']),\n",
    "    ('kw', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\",), 'keyword'),\n",
    "    ('loc', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'location'),\n",
    "    ('text', TfidfVectorizer(ngram_range=(1, 3), min_df=2, token_pattern=r\"(?u)\\b\\w+\\b\"), 'text'),\n",
    "    ('ent', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'entities'),\n",
    "    ('label', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'labels'),\n",
    "    ('dep', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_dep'),\n",
    "    ('head', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_head'),\n",
    "    ('pos', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_pos'),\n",
    "    ('child', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\"), 'ent_children'),\n",
    "    \n",
    "])\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='linear', probability=True)\n",
    "# clf = SVC(kernel='rbf', probability=True)\n",
    "# clf = SVC(kernel='poly', probability=True)\n",
    "# clf = LinearSVC(verbose=True)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=20, random_state=0) # use a guassian forest\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "# clf = RandomForestClassifier(n_estimators=500, random_state=0) # parallel all jobs\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(vec, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      4342\n",
      "           1       0.76      0.41      0.53      3271\n",
      "\n",
      "    accuracy                           0.69      7613\n",
      "   macro avg       0.72      0.66      0.65      7613\n",
      "weighted avg       0.71      0.69      0.67      7613\n",
      "\n",
      "Cross-validation MSE: 0.690 ± 0.066\n",
      "Training Set Accuracy: 0.995\n",
      "\n",
      "Evaluation Time Taken:  00:13:53\n",
      "Training Time Taken:   00:01:41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def evaluate(_clf, X, y):\n",
    "    report = classification_report(\n",
    "        y_true=y, y_pred=cross_val_predict(pipeline, X, y, cv=5)\n",
    "    )\n",
    "    print(report)\n",
    "    scores = cross_val_score(_clf, X, y, scoring='accuracy', cv=5)\n",
    "    print('Cross-validation MSE: {:.3f} ± {:.3f}'.format(np.mean(scores), 2 * np.std(scores)))\n",
    "    \n",
    "    _clf.fit(X,y)\n",
    "    print('Training Set Accuracy: {:.3f}'.format(_clf.score(X,y)))\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "evaluate(pipeline, X, y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('\\nEvaluation Time Taken: ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "\n",
    "seconds = time.time() - start_time\n",
    "print('Training Time Taken:  ', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest\n",
    "\n",
    "### 500 trees (original features):\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.67      0.90      0.77      4342\n",
    "           1       0.76      0.41      0.53      3271\n",
    "\n",
    "    accuracy                           0.69      7613\n",
    "   macro avg       0.72      0.66      0.65      7613\n",
    "weighted avg       0.71      0.69      0.67      7613\n",
    "\n",
    "Cross-validation MSE: 0.690 ± 0.066\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:13:53\n",
    "Training Time Taken:   00:01:41\n",
    "```\n",
    "\n",
    "### 200 trees (original features):\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.67      0.91      0.77      4342\n",
    "           1       0.77      0.41      0.53      3271\n",
    "\n",
    "    accuracy                           0.69      7613\n",
    "   macro avg       0.72      0.66      0.65      7613\n",
    "weighted avg       0.71      0.69      0.67      7613\n",
    "\n",
    "Cross-validation MSE: 0.692 ± 0.066\n",
    "Training Set Accuracy: 0.995\n",
    "\n",
    "Evaluation Time Taken:  00:05:43\n",
    "Training Time Taken:   00:00:45\n",
    "```\n",
    "\n",
    "### 20 trees (original features):\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.66      0.90      0.76      4342\n",
    "           1       0.75      0.39      0.51      3271\n",
    "\n",
    "    accuracy                           0.68      7613\n",
    "   macro avg       0.71      0.65      0.64      7613\n",
    "weighted avg       0.70      0.68      0.66      7613\n",
    "\n",
    "Cross-validation MSE: 0.682 ± 0.060\n",
    "Training Set Accuracy: 0.987\n",
    "\n",
    "Evaluation Time Taken:  00:00:49\n",
    "Training Time Taken:   00:00:05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rbf kernel\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.65      0.85      0.74      4342\n",
    "           1       0.67      0.40      0.50      3271\n",
    "\n",
    "    accuracy                           0.66      7613\n",
    "   macro avg       0.66      0.63      0.62      7613\n",
    "weighted avg       0.66      0.66      0.64      7613\n",
    "\n",
    "Cross-validation MSE: 0.657 ± 0.070\n",
    "Training Set Accuracy: 0.902\n",
    "\n",
    "Evaluation Time Taken: 00:09:49\n",
    "Training Time Taken:   00:01:21\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polynomial kernel\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.64      0.92      0.75      4342\n",
    "           1       0.74      0.30      0.43      3271\n",
    "\n",
    "    accuracy                           0.65      7613\n",
    "   macro avg       0.69      0.61      0.59      7613\n",
    "weighted avg       0.68      0.65      0.61      7613\n",
    "\n",
    "Cross-validation MSE: 0.655 ± 0.035\n",
    "Training Set Accuracy: 0.873\n",
    "\n",
    "Evaluation Time Taken: 00:11:37\n",
    "Training Time Taken:   00:01:15\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "1. Random forest is the best method so far;\n",
    "2. Ensemble 500 trees will cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 hongyu hongyu 64M Mar 26 00:48 ../models/random-forest-200.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "rf_mdl = '../models/random-forest-200.pkl'\n",
    "joblib.dump(pipeline, rf_mdl)\n",
    "!ls -lSh $rf_mdl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
