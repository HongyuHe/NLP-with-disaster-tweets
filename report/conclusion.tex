\section{Conclusions}
Out of all the models, Random Forests produce the best results (especially with hyperparameter tuning). This is due to the high accuracy and the short training times. The five-part pipeline serves as an excellent infrastructure for future experiments. The linear SVCs performed well, especially when the feature space is not linearly separable (baseline and non-baseline sections). Ensemble methods were beneficial when the results have high variance and bias. A higher number of features do help in terms of the classification only if the added features are relevant and carefully selected. While black-box methods hold a large amount of potential, the costs are very high compared to others.
