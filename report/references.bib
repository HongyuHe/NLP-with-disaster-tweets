@inproceedings {3,
  author = "Dumais, J. and Piatt, J. and Heckermann, J. and Sahami, M.",
  title = "Inductive learning algorithms and representations for text categorization",
  booktitle = "7th International Conference on Information and Knowledge Management",
  pages = "148-155",
  year = "1998"
}
@inproceedings {4,
  author = "Yang, Y. and Liu, X.",
  title = "A re-examination of text categorization methods",
  booktitle = "22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
  pages = "42-49",
  year = "1999"
}

  % Chapter 4: data mining classification \cite[Chapter~4]{tan}
@book {6,
  author = "Tan, PN. and Steinbach, M. and Karpatne, A. and Kumar, V.",
  title = "Introduction to Data Mining",
  edition = "2",
  publisher = "Pearson",
  year = "2006"
}

@inproceedings{x1,
  title={Comparing the Effectiveness of Support Vector Machines and Convolutional Neural Networks for Determining User Intent in Conversational Agents},
  author={O Sullivan, K.},
  year={2018}
}
@article{x2,
  author    = "Neumann, M. and King, D. and Beltagy, I. and Ammar, W.",
  title     = "ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing",
  journal   = "CoRR",
  volume    = "abs/1902.07669",
  year      = "2019",
  url       = "http://arxiv.org/abs/1902.07669",
  archivePrefix = "arXiv",
  eprint    = "1902.07669",
  timestamp = "Tue, 21 May 2019 18:03:40 +0200",
  biburl    = "https://dblp.org/rec/journals/corr/abs-1902-07669.bib",
  bibsource = "dblp computer science bibliography, https://dblp.org"
}
@misc{x3,
  title = "spaCy 101: Everything you need to know",
  %howpublished = {\url{https://spacy.io/usage/spacy-101#_title}},
  note = "Accessed: 2020-03-29"
}

@article{x4,
  author    = {Richard Maclin and
               David W. Opitz},
  title     = {Popular Ensemble Methods: An Empirical Study},
  journal   = {CoRR},
  volume    = {abs/1106.0257},
  year      = {2011},
  url       = {http://arxiv.org/abs/1106.0257},
  archivePrefix = {arXiv},
  eprint    = {1106.0257},
  timestamp = {Mon, 13 Aug 2018 16:47:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1106-0257.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{x5,
  author = {Bal, Henri and Epema, D. and Laat, Cees and Van Nieuwpoort, Rob and Romein, John and Seinstra, Frank and Snoek, Cees and Wijshoff, Harry},
  year = {2016},
  month = {05},
  pages = {54-63},
  title = {A Medium-Scale Distributed System for Computer Science Research: Infrastructure for the Long Term},
  volume = {49},
  journal = {Computer},
  doi = {10.1109/MC.2016.127}
}

@article{x6,
  author = {Ramchoun, Hassan and Amine, Mohammed and Janati Idrissi, Mohammed Amine and Ghanou, Youssef and Ettaouil, Mohamed},
  year = {2016},
  month = {01},
  pages = {26-30},
  title = {Multilayer Perceptron: Architecture Optimization and Training},
  volume = {4},
  journal = {International Journal of Interactive Multimedia and Artificial Inteligence},
  doi = {10.9781/ijimai.2016.415}
}

@article {x7,
  author = {Skocik, Michael and Collins, John and Callahan-Flintoft, Chloe and Bowman, Howard and Wyble, Brad},
  title = {I Tried a Bunch of Things: The Dangers of Unexpected Overfitting in Classification},
  elocation-id = {078816},
  year = {2016},
  doi = {10.1101/078816},
  publisher = {Cold Spring Harbor Laboratory},
  abstract = {Machine learning is a powerful set of techniques that has enhanced the abilities of neuroscientists to interpret information collected through EEG, fMRI, MEG, and PET data. With these new techniques come new dangers of overfitting that are not well understood by the neuroscience community. In this article, we use Support Vector Machine (SVM) classifiers, and genetic algorithms to demonstrate the ease by which overfitting can occur, despite the use of cross validation. We demonstrate that comparable and non-generalizable results can be obtained on informative and non-informative (i.e. random) data by iteratively modifying hyperparameters in seemingly innocuous ways. We recommend a number of techniques for limiting overfitting, such as lock boxes, blind analyses, and pre-registrations. These techniques, although uncommon in neuroscience applications, are common in many other fields that use machine learning, including computer science and physics. Adopting similar safeguards is critical for ensuring the robustness of machine-learning techniques.},
  URL = {https://www.biorxiv.org/content/early/2016/10/03/078816},
  eprint = {https://www.biorxiv.org/content/early/2016/10/03/078816.full.pdf},
  journal = {bioRxiv}
}

@article{y1,
  author    = {Dat Tien Nguyen and
               Kamla Al{-}Mannai and
               Shafiq R. Joty and
               Hassan Sajjad and
               Muhammad Imran and
               Prasenjit Mitra},
  title     = {Rapid Classification of Crisis-Related Data on Social Networks using
               Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1608.03902},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.03902},
  archivePrefix = {arXiv},
  eprint    = {1608.03902},
  timestamp = {Mon, 13 Aug 2018 16:47:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/NguyenAJSIM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{y2,
  title={Identifying and Categorizing Disaster-Related Tweets},
  author={Kevin Stowe and Michael J. Paul and Martha Palmer and Leysia Palen and Kenneth Anderson},
  booktitle={SocialNLP@EMNLP},
  year={2016}
}

@inproceedings{y3,
  title={Topical Clustering of Tweets},
  author={Kevin Dela Rosa and Rushin Shah and Bo Lin and Anatole Gershman and Robert E. Frederking},
  year={2011}
}

@inproceedings{y4,
  title={Natural Language Processing to the Rescue? Extracting "Situational Awareness" Tweets During Mass Emergency},
  author={Sudha Verma and Sarah Vieweg and William J. Corvey and Leysia Palen and James H. Martin and Martha Palmer and Aaron Schram and Kenneth Mark Anderson},
  booktitle={ICWSM},
  year={2011}
}

@misc{y5,
  author = "Hermann, K.M.",
  title = "Lecture about Deep Learning for Natural Language Processing Text Classification",
  %howpublished = {\url{https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/Lecture%205%20-%20Text%20Classification.pdf}},
  year = "2017",
  publisher = "University of Oxford"
}


@article{Japkowicz2002,
  author={Japkowicz, Nathalie
          and Stephen, Shaju},
  title={The class imbalance problem: A systematic study},
  year={2002},
  publisher={IOS Press},
  volume={6},
  pages={429-449},
  keywords={concept learning},
  keywords={class imbalances},
  keywords={re-sampling},
  keywords={misclassification costs},
  keywords={C5.0},
  keywords={Multi-Layer Perceptrons},
  keywords={Support Vector Machines},
  note={5},
  issn={1571-4128},
  doi={10.3233/IDA-2002-6504}
}

@misc{nordquist,
  author = "Nordquist, R.",
  title = "Subjects, Verbs, and Objects",
  %howpublished = {\url{https://www.thoughtco.com/subjects-verbs-and-objects-1689695}},
  year = "2020",
  publisher = "ThoughtCo"
}
@article{10,
  author = {Ali, Jehad and Khan, Rehanullah and Ahmad, Nasir and Maqsood, Imran},
  year = {2012},
  month = {09},
  pages = {},
  title = {Random Forests and Decision Trees},
  volume = {9},
  journal = {International Journal of Computer Science Issues(IJCSI)}
}
@inproceedings{8,
  title={Feature selection, perceptron learning, and a usability case study for text categorization},
  author={Hwee Tou Ng and Wei Boon Goh and Kok Leong Low},
  booktitle={SIGIR '97},
  year={1997}
}
